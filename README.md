
<h1 align="center">Hi 👋, I'm Aniket</h1>
<h3 align="center">A passionate Data Analyst from India</h3>

<p align="left"> <img src="https://komarev.com/ghpvc/?username=aniket182001&label=Profile%20views&color=0e75b6&style=flat" alt="aniket182001" /> </p>

- 🔭 I’m currently working on [Netflix Insights](https://github.com/Aniket182001/Netflix-Insights)

- 👨‍💻 All of my projects are available at [https://github.com/Aniket182001](https://github.com/Aniket182001)

- 📫 How to reach me **jobs.aniketk@gmail.com**

<br>
<h3 align="center">Netflix Insights</h3>

Netflix Insights is a data analysis project that explores and visualizes Netflix's content library. Using Python 🐍, SQL 🗃️, and Tableau 📈, it covers data cleaning, transformation, exploratory data analysis, and interactive dashboard creation to reveal trends and insights in Netflix's movies 🎬 and TV shows 📺.

<h4 align="center">◈ Module 1: Data Loading and Initial Exploration</h4>

In this module, we loaded the Netflix dataset into Python and Excel to inspect its structure and contents. The initial exploration involved displaying the first few rows and summarizing the dataset to understand its structure, data types, and basic statistics.

Key Tasks:

‣ Load data into Python and Excel.<br>
‣ Display the first few rows.<br>
‣ Summarize data types and basic statistics.<br><br>
![Data Loading](https://raw.githubusercontent.com/Aniket182001/ScreenShots/main/Data%20Loading.png) <br><br>

<h4 align="center">◈ Module 2: Data Cleaning</h4>

Data cleaning was performed to handle missing values, remove duplicates, and correct data types. Missing values were handled by filling them with appropriate values or removing rows/columns with excessive missing data.

Key Tasks:

‣ Identify and handle missing values.<br>
‣ Remove duplicate entries.<br>
‣ Correct data types.<br><br>
![Data Cleaning 1](https://raw.githubusercontent.com/Aniket182001/ScreenShots/main/Data%20Cleaning%201.png)
![Data Cleaning 2](https://raw.githubusercontent.com/Aniket182001/ScreenShots/main/Data%20Cleaning%202.png)
<br><br>

<h4 align="center">◈ Module 3: Data Transformation</h4>

This module involved creating new features and standardizing categorical variables. For instance, we extracted the year and month from the date_added field and standardized country names and categories.

Key Tasks:

‣ Create new features (e.g., extract year and month from date_added).<br>
‣ Standardize categorical variables.<br><br>

<h4 align="center">◈ Module 4: Data Analysis using SQL</h4>

The cleaned dataset was imported into a SQL database for deeper analysis. Various SQL queries were performed to extract meaningful insights such as the count of movies and TV shows, most common genres, and yearly trends of content addition.

Key Tasks:

‣ Import dataset into SQL.<br>
‣ Perform queries to extract insights.<br>
‣ Count of movies and TV shows.<br>
‣ Yearly trend of content addition.<br>
‣ Most common genres.<br>
‣ Distribution of content by country.<br><br>

<h4 align="center">◈ Module 5: Exploratory Data Analysis (EDA) in Python</h4>

EDA was performed using Python libraries such as Pandas, Matplotlib, and Seaborn. This module analyzed the distribution of content types, relationships between features, trends over time, and content ratings.

Key Tasks:

‣ Analyze the distribution of content types.<br>
‣ Study the relationship between features.<br>
‣ Identify trends over time.<br>
‣ Analyze the distribution of content ratings.<br><br>

<h4 align="center">◈ Module 6: Data Visualization in Tableau</h4>

Interactive dashboards were created using Tableau to visualize key insights from the dataset. These visualizations included the number of movies and TV shows over the years, geographic distribution of content, popular genres, and ratings distribution.

Key Tasks:

‣ Create interactive Tableau dashboards.<br>
‣ Number of movies and TV shows over the years.<br>
‣ Geographic distribution of content.<br>
‣ Popular genres and their distribution.<br>
‣ Ratings distribution and its correlation with other features.<br> <br>

![Dashboard](https://raw.githubusercontent.com/Aniket182001/ScreenShots/main/DashBoard.png)

<h4 align="center">◈ Module 7: Statistical Analysis</h4>

Basic statistical analysis was performed to derive additional insights. This included descriptive statistics, correlation analysis between numerical features, and hypothesis testing where relevant.

Key Tasks:

‣ Perform descriptive statistics (mean, median, mode).<br>
‣ Conduct correlation analysis.<br>
‣ Perform hypothesis testing.<br>









<h3 align="left">Connect with me:</h3>
<p align="left">
<a href="https://linkedin.com/in/theaniketkumbhar" target="blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/linked-in-alt.svg" alt="theaniketkumbhar" height="30" width="40" /></a>
</p>

<p><img align="left" src="https://github-readme-stats.vercel.app/api/top-langs?username=aniket182001&show_icons=true&locale=en&layout=compact" alt="aniket182001" /></p>

<p>&nbsp;<img align="center" src="https://github-readme-stats.vercel.app/api?username=aniket182001&show_icons=true&locale=en" alt="aniket182001" /></p>




